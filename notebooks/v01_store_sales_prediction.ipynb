{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:07:09.951323Z",
     "start_time": "2025-02-20T17:07:09.948795Z"
    }
   },
   "source": [
    "# 0.0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:26:17.875153Z",
     "start_time": "2025-04-25T16:26:17.870106Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:38.144942Z",
     "iopub.status.busy": "2025-05-05T21:21:38.144619Z",
     "iopub.status.idle": "2025-05-05T21:21:45.718115Z",
     "shell.execute_reply": "2025-05-05T21:21:45.716146Z",
     "shell.execute_reply.started": "2025-05-05T21:21:38.144920Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import datetime\n",
    "import inflection\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to change requirements.txt to use this versions: \n",
    " - scikit-learn 0.24 \n",
    " - numpy to 1.23.1\n",
    "   \n",
    "to be able to use sklearn MAPE function without deprecated bool errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:07:09.951323Z",
     "start_time": "2025-02-20T17:07:09.948795Z"
    }
   },
   "source": [
    "## 0.1. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:05:33.263692Z",
     "start_time": "2025-04-25T16:05:33.256644Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:45.720859Z",
     "iopub.status.busy": "2025-05-05T21:21:45.720427Z",
     "iopub.status.idle": "2025-05-05T21:21:45.733599Z",
     "shell.execute_reply": "2025-05-05T21:21:45.732341Z",
     "shell.execute_reply.started": "2025-05-05T21:21:45.720831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define function to calculate cramer v \n",
    "def cramerv(x,y):\n",
    "    cm = pd.crosstab(x,y).values\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "\n",
    "    chi2 = stats.chi2_contingency(cm)[0]\n",
    "    chis2corr = max(0, chi2 - (k-1)*(r-1)/(n-1))\n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt((chis2corr/n) / min(kcorr-1, rcorr-1))\n",
    "\n",
    "def ml_error (model_name: str, y: pd.Series, yhat: pd.Series) -> pd.DataFrame:\n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    mape = mean_absolute_percentage_error(y, yhat)\n",
    "    rmse = np.sqrt(mean_absolute_error(y, yhat))\n",
    "    \n",
    "    return pd.DataFrame({'Model Name': model_name,\n",
    "                         'MAE': mae,\n",
    "                         'MAPE': mape,\n",
    "                         'RMSE': rmse}, index=[0])    \n",
    "\n",
    "def jupyter_settings():\n",
    "    %matplotlib inline\n",
    "    # %pylab inline\n",
    "    plt.style.use( 'bmh' )\n",
    "    plt.rcParams['figure.figsize'] = [25, 12]\n",
    "    plt.rcParams['font.size'] = 24\n",
    "    display( HTML( '<style>.container { width:100% !important; }</style>') )\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.max_rows = None\n",
    "    pd.set_option( 'display.expand_frame_repr', False )\n",
    "\n",
    "\n",
    "    \n",
    "    # Setting as default the seaborn theme for plots (only necessary for old versions of seaborn, this is deprecated)\n",
    "    sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:05:33.288228Z",
     "start_time": "2025-04-25T16:05:33.265495Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:45.734759Z",
     "iopub.status.busy": "2025-05-05T21:21:45.734500Z",
     "iopub.status.idle": "2025-05-05T21:21:45.875229Z",
     "shell.execute_reply": "2025-05-05T21:21:45.874250Z",
     "shell.execute_reply.started": "2025-05-05T21:21:45.734742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jupyter_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:07:09.951323Z",
     "start_time": "2025-02-20T17:07:09.948795Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## 0.2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:05:34.107569Z",
     "start_time": "2025-04-25T16:05:33.291881Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:45.877505Z",
     "iopub.status.busy": "2025-05-05T21:21:45.877248Z",
     "iopub.status.idle": "2025-05-05T21:21:48.105814Z",
     "shell.execute_reply": "2025-05-05T21:21:48.103177Z",
     "shell.execute_reply.started": "2025-05-05T21:21:45.877485Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_sales_raw = pd.read_csv('../data/train.csv', low_memory=False)\n",
    "df_test_raw = pd.read_csv('../data/test.csv', low_memory=False)\n",
    "df_store_raw = pd.read_csv('../data/store.csv', low_memory=False)\n",
    "\n",
    "# Merge\n",
    "df_raw = pd.merge(df_sales_raw, df_store_raw, how='left', on='Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-20T17:07:09.951323Z",
     "start_time": "2025-02-20T17:07:09.948795Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# 1.0. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.1. Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:05:34.298179Z",
     "start_time": "2025-04-25T16:05:34.109391Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:48.106639Z",
     "iopub.status.busy": "2025-05-05T21:21:48.106434Z",
     "iopub.status.idle": "2025-05-05T21:21:48.268166Z",
     "shell.execute_reply": "2025-05-05T21:21:48.266419Z",
     "shell.execute_reply.started": "2025-05-05T21:21:48.106622Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw_1 = df_raw.copy()\n",
    "\n",
    "old_cols = ['Store', 'DayOfWeek', 'Date', 'Sales', 'Customers', 'Open', 'Promo',\n",
    "           'StateHoliday', 'SchoolHoliday', 'StoreType', 'Assortment',\n",
    "           'CompetitionDistance', 'CompetitionOpenSinceMonth',\n",
    "           'CompetitionOpenSinceYear', 'Promo2', 'Promo2SinceWeek',\n",
    "           'Promo2SinceYear', 'PromoInterval']\n",
    "\n",
    "# Changing columns to snakecase\n",
    "snakecase = lambda x: inflection.underscore(x)\n",
    "new_cols = list(map(snakecase, old_cols))\n",
    "\n",
    "# Rename columns\n",
    "df_raw_1.columns = new_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.2. Data dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:05:34.305699Z",
     "start_time": "2025-04-25T16:05:34.300736Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:48.269191Z",
     "iopub.status.busy": "2025-05-05T21:21:48.268975Z",
     "iopub.status.idle": "2025-05-05T21:21:48.634699Z",
     "shell.execute_reply": "2025-05-05T21:21:48.632212Z",
     "shell.execute_reply.started": "2025-05-05T21:21:48.269173Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1017209, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.3. Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:05:34.520535Z",
     "start_time": "2025-04-25T16:05:34.308346Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:48.636613Z",
     "iopub.status.busy": "2025-05-05T21:21:48.636219Z",
     "iopub.status.idle": "2025-05-05T21:21:49.093936Z",
     "shell.execute_reply": "2025-05-05T21:21:49.092360Z",
     "shell.execute_reply.started": "2025-05-05T21:21:48.636579Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1017209 entries, 0 to 1017208\n",
      "Data columns (total 18 columns):\n",
      " #   Column                        Non-Null Count    Dtype  \n",
      "---  ------                        --------------    -----  \n",
      " 0   store                         1017209 non-null  int64  \n",
      " 1   day_of_week                   1017209 non-null  int64  \n",
      " 2   date                          1017209 non-null  object \n",
      " 3   sales                         1017209 non-null  int64  \n",
      " 4   customers                     1017209 non-null  int64  \n",
      " 5   open                          1017209 non-null  int64  \n",
      " 6   promo                         1017209 non-null  int64  \n",
      " 7   state_holiday                 1017209 non-null  object \n",
      " 8   school_holiday                1017209 non-null  int64  \n",
      " 9   store_type                    1017209 non-null  object \n",
      " 10  assortment                    1017209 non-null  object \n",
      " 11  competition_distance          1014567 non-null  float64\n",
      " 12  competition_open_since_month  693861 non-null   float64\n",
      " 13  competition_open_since_year   693861 non-null   float64\n",
      " 14  promo2                        1017209 non-null  int64  \n",
      " 15  promo2_since_week             509178 non-null   float64\n",
      " 16  promo2_since_year             509178 non-null   float64\n",
      " 17  promo_interval                509178 non-null   object \n",
      "dtypes: float64(5), int64(8), object(5)\n",
      "memory usage: 139.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_raw_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:05:34.590293Z",
     "start_time": "2025-04-25T16:05:34.522814Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:49.095357Z",
     "iopub.status.busy": "2025-05-05T21:21:49.095026Z",
     "iopub.status.idle": "2025-05-05T21:21:49.244666Z",
     "shell.execute_reply": "2025-05-05T21:21:49.243189Z",
     "shell.execute_reply.started": "2025-05-05T21:21:49.095338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# change date to datetime64\n",
    "df_raw_1['date'] = pd.to_datetime(df_raw_1['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.4. Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:05:34.730916Z",
     "start_time": "2025-04-25T16:05:34.592982Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:49.247360Z",
     "iopub.status.busy": "2025-05-05T21:21:49.246306Z",
     "iopub.status.idle": "2025-05-05T21:21:49.543170Z",
     "shell.execute_reply": "2025-05-05T21:21:49.541553Z",
     "shell.execute_reply.started": "2025-05-05T21:21:49.247334Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store                                0\n",
       "day_of_week                          0\n",
       "date                                 0\n",
       "sales                                0\n",
       "customers                            0\n",
       "open                                 0\n",
       "promo                                0\n",
       "state_holiday                        0\n",
       "school_holiday                       0\n",
       "store_type                           0\n",
       "assortment                           0\n",
       "competition_distance              2642\n",
       "competition_open_since_month    323348\n",
       "competition_open_since_year     323348\n",
       "promo2                               0\n",
       "promo2_since_week               508031\n",
       "promo2_since_year               508031\n",
       "promo_interval                  508031\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking NA count explicitly\n",
    "df_raw_1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.5. Fillout NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:06:58.331909Z",
     "start_time": "2025-04-25T16:05:34.734685Z"
    },
    "execution": {
     "iopub.execute_input": "2025-05-05T21:21:49.547244Z",
     "iopub.status.busy": "2025-05-05T21:21:49.546344Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# competition_distance \n",
    "df_raw_1['competition_distance'].fillna(200000.0, inplace=True)\n",
    "\n",
    "# competition_open_since_month \n",
    "\n",
    "    # Usar a bilbioteca math quando quiser aplicar soluções de substituição de NaN através de lambda function nas linhas, fillna\n",
    "    # e replace não funcionam pois são feitas para atuar unicamente em dataframes.\n",
    "\n",
    "df_raw_1['competition_open_since_month'] = (df_raw_1.apply(lambda x: x['date'].month \n",
    "                                                           if math.isnan(x['competition_open_since_month']) \n",
    "                                                           else x['competition_open_since_month'] , axis=1))\n",
    "\n",
    "# competition_open_since_year     \n",
    "\n",
    "df_raw_1['competition_open_since_year'] = (df_raw_1.apply(lambda x: x['date'].year \n",
    "                                                           if math.isnan(x['competition_open_since_year']) \n",
    "                                                           else x['competition_open_since_year'] , axis=1))\n",
    "# promo2_since_week  \n",
    "\n",
    "df_raw_1['promo2_since_week'] = (df_raw_1.apply(lambda x: x['date'].week  \n",
    "                                                if math.isnan(x['promo2_since_week']) \n",
    "                                                else x['promo2_since_week'] , axis=1))\n",
    "\n",
    "# promo2_since_year\n",
    "\n",
    "df_raw_1['promo2_since_year'] = (df_raw_1.apply(lambda x: x['date'].year  \n",
    "                                                if math.isnan(x['promo2_since_year']) \n",
    "                                                else x['promo2_since_year'] , axis=1))\n",
    "\n",
    "# promo_interval \n",
    "\n",
    "month_map = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug', 9: 'Set', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "\n",
    "df_raw_1['promo_interval'].fillna(0, inplace=True)\n",
    "\n",
    "df_raw_1['month_map'] = df_raw_1['date'].dt.month.map(month_map)\n",
    "\n",
    "df_raw_1['is_promo'] = df_raw_1[['promo_interval', 'month_map']].apply(lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:06:58.357322Z",
     "start_time": "2025-04-25T16:06:58.334847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw_1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1.6 Reviewing Columns Types and Missing values again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:06:58.599290Z",
     "start_time": "2025-04-25T16:06:58.359514Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:06:58.632470Z",
     "start_time": "2025-04-25T16:06:58.601340Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw_1['competition_open_since_month'] = df_raw_1['competition_open_since_month'].astype(int)\n",
    "df_raw_1['competition_open_since_year'] = df_raw_1['competition_open_since_year'].astype(int)\n",
    "\n",
    "df_raw_1['promo2_since_week'] = df_raw_1['promo2_since_week'].astype(int)\n",
    "df_raw_1['promo2_since_year'] = df_raw_1['promo2_since_year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:06:58.719804Z",
     "start_time": "2025-04-25T16:06:58.635115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw_1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-21T19:00:44.741149Z",
     "start_time": "2025-02-21T19:00:44.737515Z"
    },
    "hidden": true
   },
   "source": [
    "## 1.7 Descriptive Statistical Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:06:58.879347Z",
     "start_time": "2025-04-25T16:06:58.722592Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_raw_1.select_dtypes('number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:06:59.024182Z",
     "start_time": "2025-04-25T16:06:58.882117Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_attributes = df_raw_1.select_dtypes(include=['int64', 'float64'])\n",
    "cat_attributes = df_raw_1.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.7.1 Numeric Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:06:59.147364Z",
     "start_time": "2025-04-25T16:06:59.027480Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# central tendency - mean, median\n",
    "# ct1 = pd.DataFrame(num_attributes.apply(np.mean)).T\n",
    "# ct2 = pd.DataFrame(num_attributes.apply(np.median)).T\n",
    "\n",
    "# dispersion - std, variance, min, max, skew, kurtosis\n",
    "\n",
    "# d1 = pd.DataFrame(num_attributes.apply(np.std)).T\n",
    "# d2 = pd.DataFrame(num_attributes.apply(min())).T\n",
    "# d3 = pd.DataFrame(num_attributes.apply(max())).T\n",
    "# d4 = pd.DataFrame(num_attributes.apply(lambda x: (x.max() - x.min())).T\n",
    "# d5 = pd.DataFrame(num_attributes.apply(lambda x: x.skew())).T\n",
    "# d6 = pd.DataFrame(num_attributes.apply(lambda x: x.kurtosis())).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:00.193828Z",
     "start_time": "2025-04-25T16:06:59.150461Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "range_ = lambda x: (x.max() - x.min())\n",
    "\n",
    "m = num_attributes.agg([np.mean, np.median, np.std, 'min', 'max', range_, 'skew', 'kurt']).T\n",
    "m.rename(columns = {'<lambda>': 'range', 'kurt': 'kurtosis'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:02.904895Z",
     "start_time": "2025-04-25T16:07:00.196944Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(df_raw_1['sales'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:04.950025Z",
     "start_time": "2025-04-25T16:07:02.907677Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(df_raw_1['competition_distance'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 1.7.2 Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:05.046510Z",
     "start_time": "2025-04-25T16:07:04.952324Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cat_attributes.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:05.876748Z",
     "start_time": "2025-04-25T16:07:05.049454Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aux1 = df_raw_1[(df_raw_1['state_holiday'] != '0') & (df_raw_1['sales'] > 0)]\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.boxplot(x= 'state_holiday', y= 'sales', data= aux1)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.boxplot(x= 'store_type', y= 'sales', data= aux1)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.boxplot(x= 'assortment', y= 'sales', data= aux1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2.0. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:05.965678Z",
     "start_time": "2025-04-25T16:07:05.879827Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df_raw_1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1. Hypothesis Mind Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:06.108191Z",
     "start_time": "2025-04-25T16:07:05.967852Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fazer o mapa no Coggle e importar com Ipython.core image library\n",
    "Image('../img/mindmap_hypothesis.png', width= 800, height= 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Hypothesis Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:06.113776Z",
     "start_time": "2025-04-25T16:07:06.110775Z"
    }
   },
   "outputs": [],
   "source": [
    "# Brainstorm reunion or making up by yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Store Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Lojas com número maior de funcionários deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com maior capacidade de estoque deveriam vender mais.\n",
    "\n",
    "**3.** Lojas com maior porte deveriam vender mais.\n",
    "\n",
    "**4.** Lojas com maior sortimentos deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "\n",
    "**6.** Lojas com competidores à mais tempo deveriam vendem mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Product Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Lojas que investem mais em Marketing deveriam vender mais.\n",
    "    \n",
    "**2.** Lojas com maior exposição de produto deveriam vender mais.\n",
    "\n",
    "**3.** Lojas com produtos com preço menor deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com promoções mais agressivas ( descontos maiores ), deveriam vender mais.\n",
    "\n",
    "**6.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "\n",
    "**7.** Lojas com mais dias de promoção deveriam vender mais.\n",
    "    \n",
    "**8.** Lojas com mais promoções consecutivas deveriam vender mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Time Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "\n",
    "**2.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**3.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**4.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**5.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**6.** Lojas deveriam vender menos durante os feriados escolares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.3. Final Hypothesis List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selection of highest priority hypothesis**\n",
    "\n",
    "**1.** Lojas com maior sortimentos deveriam vender mais.\n",
    "\n",
    "**2.** Lojas com competidores mais próximos deveriam vender menos.\n",
    "\n",
    "**3.** Lojas com competidores à mais tempo deveriam vendem mais.\n",
    "\n",
    "**4.** Lojas com promoções ativas por mais tempo deveriam vender mais.\n",
    "\n",
    "**5.** Lojas com mais dias de promoção deveriam vender mais.\n",
    "\n",
    "**7.** Lojas com mais promoções consecutivas deveriam vender mais.\n",
    "\n",
    "**8.** Lojas abertas durante o feriado de Natal deveriam vender mais.\n",
    "\n",
    "**9.** Lojas deveriam vender mais ao longo dos anos.\n",
    "\n",
    "**10.** Lojas deveriam vender mais no segundo semestre do ano.\n",
    "\n",
    "**11.** Lojas deveriam vender mais depois do dia 10 de cada mês.\n",
    "\n",
    "**12.** Lojas deveriam vender menos aos finais de semana.\n",
    "\n",
    "**13.** Lojas deveriam vender menos durante os feriados escolares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.4. Feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:35.429949Z",
     "start_time": "2025-04-25T16:07:06.116073Z"
    }
   },
   "outputs": [],
   "source": [
    "#year\n",
    "df2['year'] = df2['date'].dt.year\n",
    "\n",
    "#month\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "#day\n",
    "df2['day'] = df2['date'].dt.day\n",
    "\n",
    "#week of year\n",
    "df2['week_of_year'] = df2['date'].dt.weekofyear\n",
    "\n",
    "# year - week (mask)\n",
    "df2['year_week'] = df2['date'].dt.strftime('%Y-%W')\n",
    "\n",
    "#competition since\n",
    "df2['competition_since'] = df2.apply(lambda x: datetime.datetime(year=x['competition_open_since_year'], month=x['competition_open_since_month'], day=1), axis=1)\n",
    "\n",
    "# versão simplificada do script da aula\n",
    "df2['competition_time_month'] = ((df2['date'] - df2['competition_since'])/30).dt.days\n",
    "\n",
    "# converte ano-semana da promo em data da promo e calcula a diferença entre a data da promo e a data do registro de venda \n",
    "df2['promo_since'] = df2['promo2_since_year'].astype(str) + '-' + df2['promo2_since_week'].astype(str)\n",
    "df2['promo_since'] = df2['promo_since'].apply(lambda x: datetime.datetime.strptime(x + '-1', '%Y-%W-%w') - datetime.timedelta(days=7))\n",
    "df2['promo_time_week'] = ((df2['date'] - df2['promo_since'])/7).dt.days\n",
    "\n",
    "#assortment\n",
    "df2['assortment'] = df2['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x == 'b' else 'extended')\n",
    "df2['state_holiday'] = df2['state_holiday'].apply(lambda x: 'public_holiday' if x == 'a' else 'easter_holiday' if x == 'b' else 'christmas' if x == 'c' else 'regular_day')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:35.438386Z",
     "start_time": "2025-04-25T16:07:35.433272Z"
    }
   },
   "outputs": [],
   "source": [
    "# versão que eu acho correta usando o módulo da diferença\n",
    "# (np.abs((df2['date'] - df2['competition_since'])/30)).dt.days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:35.495276Z",
     "start_time": "2025-04-25T16:07:35.445441Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3.0. Variable Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Row filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:35.663498Z",
     "start_time": "2025-04-25T16:07:35.498008Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:35.762224Z",
     "start_time": "2025-04-25T16:07:35.666505Z"
    }
   },
   "outputs": [],
   "source": [
    "df3 = df3[(df3['open'] != 0) & (df3['sales'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Column selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:35.831046Z",
     "start_time": "2025-04-25T16:07:35.765250Z"
    }
   },
   "outputs": [],
   "source": [
    "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
    "df3 = df3.drop(cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4.0. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:35.887453Z",
     "start_time": "2025-04-25T16:07:35.833100Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1.1 Response Variable (Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:37.858377Z",
     "start_time": "2025-04-25T16:07:35.889793Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot(df4['sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1.2 Numerical Variables Histogram (All Numerical features vs Response variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:41.201025Z",
     "start_time": "2025-04-25T16:07:37.860857Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes.hist(bins=25);\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1.3 Categorial Variables Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:41.227448Z",
     "start_time": "2025-04-25T16:07:41.203425Z"
    }
   },
   "outputs": [],
   "source": [
    "df4['state_holiday'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:52.680087Z",
     "start_time": "2025-04-25T16:07:41.229482Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(3,2,1)\n",
    "cutted = df4[df4['state_holiday'] != 'regular_day']\n",
    "sns.countplot(cutted['state_holiday'])\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "sns.kdeplot(df4[df4['state_holiday'] == 'public_holiday']['sales'], label='public_holiday', shade=True)\n",
    "sns.kdeplot(df4[df4['state_holiday'] == 'easter_holiday']['sales'], label='easter_holiday', shade=True)\n",
    "sns.kdeplot(df4[df4['state_holiday'] == 'christmas']['sales'], label='christmas', shade=True)\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "sns.countplot(df4['store_type'])\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "sns.kdeplot(df3[df4['store_type'] == 'a']['sales'], label='a', shade=True)\n",
    "sns.kdeplot(df4[df4['store_type'] == 'b']['sales'], label='b', shade=True)\n",
    "sns.kdeplot(df4[df4['store_type'] == 'c']['sales'], label='c', shade=True)\n",
    "sns.kdeplot(df4[df4['store_type'] == 'd']['sales'], label='d', shade=True)\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "sns.countplot(df4['assortment'])\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "sns.kdeplot(df3[df4['assortment'] == 'extended']['sales'], label='extended', shade=True)\n",
    "sns.kdeplot(df4[df4['assortment'] == 'basic']['sales'], label='basic', shade=True)\n",
    "sns.kdeplot(df4[df4['assortment'] == 'extra']['sales'], label='extra', shade=True)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.2. Bivariate Analysis (Hypothesis Validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H1. Lojas com maior sortimentos deveriam vender mais.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FALSA** Lojas com MAIOR SORTIMENTO vendem MENOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:53.198756Z",
     "start_time": "2025-04-25T16:07:52.682904Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['assortment', 'sales']].groupby( 'assortment' ).sum().reset_index()\n",
    "sns.barplot( x='assortment', y='sales', data=aux1 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:53.861677Z",
     "start_time": "2025-04-25T16:07:53.200830Z"
    }
   },
   "outputs": [],
   "source": [
    "aux2 = df4[['year_week', 'assortment', 'sales']].groupby(['year_week','assortment'] ).sum().reset_index()\n",
    "aux2.pivot( index='year_week', columns='assortment', values='sales' ).plot();\n",
    "plt.ylabel('sales');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:54.380353Z",
     "start_time": "2025-04-25T16:07:53.864937Z"
    }
   },
   "outputs": [],
   "source": [
    "aux3 = aux2[aux2['assortment'] == 'extra']\n",
    "aux3.pivot( index='year_week', columns='assortment', values='sales' ).plot()\n",
    "plt.ylabel('sales');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H2. Lojas com competidores mais próximos deveriam vender menos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FALSA** Lojas com COMPETIDORES MAIS PRÓXIMOS vendem MAIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:55.567216Z",
     "start_time": "2025-04-25T16:07:54.383755Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['competition_distance', 'sales']].groupby( 'competition_distance' ).sum().reset_index()\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.scatterplot( x ='competition_distance', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "bins = list( np.arange( 0, 20000, 1000) )\n",
    "\n",
    "aux1['competition_distance_binned'] = pd.cut( aux1['competition_distance'], bins=bins )\n",
    "aux2 = aux1[['competition_distance_binned', 'sales']].groupby('competition_distance_binned' ).sum().reset_index()\n",
    "\n",
    "sns.barplot( x='competition_distance_binned', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H3. Lojas com competidores à mais tempo deveriam vendem mais.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FALSA** Lojas com COMPETIDORES À MAIS TEMPO vendem MENOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:07:59.006040Z",
     "start_time": "2025-04-25T16:07:55.569839Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot( 1, 3, 1 )\n",
    "aux1 = df4[['competition_time_month', 'sales']].groupby('competition_time_month' ).sum().reset_index()\n",
    "aux2 = aux1[( aux1['competition_time_month'] < 120 ) & (aux1['competition_time_month'] != 0 )]\n",
    "sns.barplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='competition_time_month', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "x = sns.heatmap( aux1.corr( method='pearson'), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H4. Lojas com promoções ativas por mais tempo deveriam vender mais.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FALSA Lojas com promocoes ativas por mais tempo vendem menos, depois de um certo periodo\n",
    "de promocao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:07.637695Z",
     "start_time": "2025-04-25T16:07:59.010195Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['promo_time_week', 'sales']].groupby( 'promo_time_week').sum().reset_index()\n",
    "\n",
    "grid = plt.GridSpec( 2, 3 )\n",
    "\n",
    "plt.subplot( grid[0,0] )\n",
    "aux2 = aux1[aux1['promo_time_week'] > 0] # promo extendido\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[0,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux2 );\n",
    "\n",
    "plt.subplot( grid[1,0] )\n",
    "aux3 = aux1[aux1['promo_time_week'] < 0] # promo regular\n",
    "sns.barplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "plt.xticks( rotation=90 );\n",
    "\n",
    "plt.subplot( grid[1,1] )\n",
    "sns.regplot( x='promo_time_week', y='sales', data=aux3 );\n",
    "\n",
    "plt.subplot( grid[:,2] )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H5. Lojas com mais dias de promoção deveriam vender mais.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H6. Lojas com mais promoções consecutivas deveriam vender mais.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FALSA Lojas com mais promocoes consecutivas vendem menos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:07.686954Z",
     "start_time": "2025-04-25T16:08:07.641668Z"
    }
   },
   "outputs": [],
   "source": [
    "df4[['promo', 'promo2', 'sales']].groupby( ['promo', 'promo2'] ).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:08.351611Z",
     "start_time": "2025-04-25T16:08:07.689195Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year_week','sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "ax = aux1.plot()\n",
    "aux2 = df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 0 )][['year_week','sales']].groupby( 'year_week' ).sum().reset_index()\n",
    "aux2.plot( ax=ax )\n",
    "ax.legend( labels=['Traditional & Extended', 'Extended']);\n",
    "plt.xlabel('year_week');\n",
    "plt.ylabel('sales');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H7. Lojas abertas durante o feriado de Natal deveriam vender mais.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FALSA Lojas abertas durante o feriado do Natal vendem menos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:08.963765Z",
     "start_time": "2025-04-25T16:08:08.353593Z"
    }
   },
   "outputs": [],
   "source": [
    "aux = df4[df4['state_holiday'] != 'regular_day']\n",
    "\n",
    "plt.subplot( 1, 2, 1 )\n",
    "aux1 = aux[['state_holiday', 'sales']].groupby( 'state_holiday' ).sum().reset_index()\n",
    "sns.barplot( x='state_holiday', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 2, 2 )\n",
    "aux2 = aux[['year', 'state_holiday', 'sales']].groupby( ['year','state_holiday'] ).sum().reset_index()\n",
    "sns.barplot( x='year', y='sales', hue='state_holiday', data=aux2 );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H8. Lojas deveriam vender mais ao longo dos anos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FALSA Lojas vendem menos ao longo dos anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:09.856485Z",
     "start_time": "2025-04-25T16:08:08.966463Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['year', 'sales']].groupby( 'year' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='year', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H9. Lojas deveriam vender mais no segundo semestre do ano.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FALSA Lojas vendem menos no segundo semestre do ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:10.748625Z",
     "start_time": "2025-04-25T16:08:09.859402Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['month', 'sales']].groupby( 'month' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='month', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H10. Lojas deveriam vender mais depois do dia 10 de cada mês.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERDADEIRA Lojas vendem mais depois do dia 10 de cada mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:11.928539Z",
     "start_time": "2025-04-25T16:08:10.751456Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day', 'sales']].groupby( 'day' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 2, 2, 1 )\n",
    "sns.barplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 2 )\n",
    "sns.regplot( x='day', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 2, 2, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );\n",
    "\n",
    "aux1['before_after'] = aux1['day'].apply( lambda x: 'before_10_days' if x <= 10 else 'after_10_days' )\n",
    "aux2 =aux1[['before_after', 'sales']].groupby( 'before_after' ).sum().reset_index()\n",
    "plt.subplot( 2, 2, 4 )\n",
    "sns.barplot( x='before_after', y='sales', data=aux2 );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H11. Lojas deveriam vender menos aos finais de semana.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERDADEIRA Lojas vendem menos nos final de semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:12.787297Z",
     "start_time": "2025-04-25T16:08:11.931304Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['day_of_week', 'sales']].groupby( 'day_of_week' ).sum().reset_index()\n",
    "\n",
    "plt.subplot( 1, 3, 1 )\n",
    "sns.barplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 2 )\n",
    "sns.regplot( x='day_of_week', y='sales', data=aux1 );\n",
    "\n",
    "plt.subplot( 1, 3, 3 )\n",
    "sns.heatmap( aux1.corr( method='pearson' ), annot=True );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **H12. Lojas deveriam vender menos durante os feriados escolares.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERDADEIRA Lojas vendem menos durante os feriadso escolares, except os meses de Julho e Agosto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:13.456971Z",
     "start_time": "2025-04-25T16:08:12.789832Z"
    }
   },
   "outputs": [],
   "source": [
    "aux1 = df4[['school_holiday', 'sales']].groupby( 'school_holiday' ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 1 )\n",
    "sns.barplot( x='school_holiday', y='sales', data=aux1 );\n",
    "\n",
    "aux2 = df4[['month', 'school_holiday', 'sales']].groupby(['month','school_holiday'] ).sum().reset_index()\n",
    "plt.subplot( 2, 1, 2 )\n",
    "sns.barplot( x='month', y='sales', hue='school_holiday', data=aux2 );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Hypothesis validation summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:13.466256Z",
     "start_time": "2025-04-25T16:08:13.460033Z"
    }
   },
   "outputs": [],
   "source": [
    "tab = [['Hypothesis', 'Conclusion', 'Relevancy'],\n",
    "    ['H1', 'Falsa', 'Baixa'],\n",
    "    ['H2', 'Falsa', 'Media'],\n",
    "    ['H3', 'Falsa', 'Media'],\n",
    "    ['H4', 'Falsa', 'Baixa'],\n",
    "    ['H5', '-', '-'],\n",
    "    ['H7', 'Falsa', 'Baixa'],\n",
    "    ['H8', 'Falsa', 'Media'],\n",
    "    ['H9', 'Falsa', 'Alta'],\n",
    "    ['H10', 'Falsa', 'Alta'],\n",
    "    ['H11', 'Verdadeira', 'Alta'],\n",
    "    ['H12', 'Verdadeira', 'Alta'],\n",
    "    ['H13', 'Verdadeira', 'Baixa'],\n",
    "]\n",
    "print( tabulate( tab, headers='firstrow' ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3.1 Numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:13.507084Z",
     "start_time": "2025-04-25T16:08:13.468906Z"
    }
   },
   "outputs": [],
   "source": [
    "num_attributes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:14.874620Z",
     "start_time": "2025-04-25T16:08:13.509781Z"
    }
   },
   "outputs": [],
   "source": [
    "correlation = num_attributes.corr(method = 'pearson')\n",
    "sns.heatmap(correlation, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:15.572249Z",
     "start_time": "2025-04-25T16:08:14.878208Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting only categorical columns\n",
    "cat_features = df4.select_dtypes(include= 'object')\n",
    "\n",
    "# Calculate cramer V for every combination of cat variables\n",
    "a1 = cramerv(cat_features['state_holiday'], cat_features['state_holiday'])\n",
    "a2 = cramerv(cat_features['state_holiday'], cat_features['store_type'])\n",
    "a3 = cramerv(cat_features['state_holiday'], cat_features['assortment'])\n",
    "\n",
    "a4 = cramerv(cat_features['store_type'], cat_features['state_holiday'])\n",
    "a5 = cramerv(cat_features['store_type'], cat_features['store_type'])\n",
    "a6 = cramerv(cat_features['store_type'], cat_features['assortment'])\n",
    "\n",
    "a7 = cramerv(cat_features['assortment'], cat_features['state_holiday'])\n",
    "a8 = cramerv(cat_features['assortment'], cat_features['store_type'])\n",
    "a9 = cramerv(cat_features['assortment'], cat_features['assortment'])\n",
    "\n",
    "# Final dataset\n",
    "d = pd.DataFrame({\n",
    "    'state_holiday': [a1, a2, a3],\n",
    "    'store_type': [a4, a5, a6],\n",
    "    'assortment': [a7, a8, a9]})\n",
    "\n",
    "d = d.set_index(d.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:16.081163Z",
     "start_time": "2025-04-25T16:08:15.575960Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(d, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5.0 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:16.128964Z",
     "start_time": "2025-04-25T16:08:16.083947Z"
    }
   },
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into our numerical variables histograms we saw that none of them had a normal distribution, so we can skip this step, as applying normalization on data that do not origginally has some degree of normal distribution may impact the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Rescaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:15.017573Z",
     "start_time": "2025-04-25T16:08:14.846732Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rs = RobustScaler()\n",
    "mms = MinMaxScaler()\n",
    "\n",
    "# competition_distance\n",
    "df5['competition_distance'] = rs.fit_transform(df5[['competition_distance']].values)\n",
    "\n",
    "# competition_time_month \n",
    "df5['competition_time_month'] = rs.fit_transform(df5[['competition_time_month']].values)\n",
    "\n",
    "# promo_time_week\n",
    "df5['promo_time_week'] = mms.fit_transform(df5[['promo_time_week']].values)\n",
    "\n",
    "# year\n",
    "df5['year'] = mms.fit_transform(df5[['year']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 5.3.1 Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:24:24.944085Z",
     "start_time": "2025-04-25T16:24:23.637686Z"
    }
   },
   "outputs": [],
   "source": [
    "# state_holiday - One hot encoding\n",
    "df5 = pd.get_dummies(df5, prefix= ['state_holiday'], columns= ['state_holiday'])\n",
    "\n",
    "# store_type - Label Encoding\n",
    "le = LabelEncoder()\n",
    "\n",
    "df5['store_type'] = le.fit_transform(df5['store_type'])\n",
    "\n",
    "# assortment - Ordinal enconding (manual)\n",
    "assortment_dict = {'basic': 1,\n",
    "                   'extra': 2,\n",
    "                   'extended': 3}\n",
    "\n",
    "df5['assortment'] = df5['assortment'].map(assortment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Response variable transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:57:05.080996Z",
     "start_time": "2025-04-25T16:57:04.998069Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changing the actual distribution of the target variable to a more normal distribution using log transf.\n",
    "df5['sales'] = np.log1p(df5['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T17:05:00.624088Z",
     "start_time": "2025-04-25T17:04:56.515230Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Before', fontsize= 18)\n",
    "sns.distplot(df4['sales'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('After', fontsize= 18)\n",
    "sns.distplot(df5['sales'])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Nature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:08:15.023774Z",
     "start_time": "2025-04-25T16:08:15.020854Z"
    }
   },
   "outputs": [],
   "source": [
    "# month\n",
    "df5['month_sin'] = df5['month'].apply(lambda x: np.sin(x * (2*np.pi / 12) ))\n",
    "df5['month_cos'] = df5['month'].apply(lambda x: np.cos(x * (2*np.pi / 12) ))\n",
    "\n",
    "# day \n",
    "df5['day_sin'] = df5['day'].apply(lambda x: np.sin(x * (2*np.pi / 30) ))\n",
    "df5['day_cos'] = df5['day'].apply(lambda x: np.cos(x * (2*np.pi / 30) ))\n",
    "\n",
    "# week_of_year\n",
    "df5['week_of_year_sin'] = df5['week_of_year'].apply(lambda x: np.sin(x * (2*np.pi / 52) ))\n",
    "df5['week_of_year_cos'] = df5['week_of_year'].apply(lambda x: np.cos(x * (2*np.pi / 52) ))\n",
    "\n",
    "# day_of_week\n",
    "df5['day_of_week_sin'] = df5['day_of_week'].apply(lambda x: np.sin(x * (2*np.pi / 7) ))\n",
    "df5['day_of_week_cos'] = df5['day_of_week'].apply(lambda x: np.cos(x * (2*np.pi / 7) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping redundant columns that result from feature engineering \n",
    "cols_drop = ['day_of_week', 'week_of_year', 'year_week', 'day', 'month', 'promo_since', 'competition_since']\n",
    "df6 = df6.drop(cols_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Spliting dataframe into Train-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this case, the split will be such that the training dataset includes all rows from the first recorded date to six weeks prior to the last recorded date. The test split will consist of the remaining data up to the actual last date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão do curso, remover posteriormente\n",
    "#df6[['store', 'date']].groupby('store').max().reset_index()['date'][0] - datetime.timedelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['date'].max() - datetime.timedelta(weeks = 6)\n",
    "\n",
    "# Training dataset\n",
    "X_train = df6[df6['date'] < '2015-06-19']\n",
    "y_train = X_train['sales']\n",
    "\n",
    "# Test dataset\n",
    "X_test = df6[df6['date'] >= '2015-06-19']\n",
    "y_test = X_test['sales']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Train date {}'.format(X_train['date'].min()))\n",
    "print('Max Train date {}'.format(X_train['date'].max()))\n",
    "\n",
    "print('\\nMin Test date {}'.format(X_test['date'].min()))\n",
    "print('Max Test date {}'.format(X_test['date'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Using Boruta algorithm as feature selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting dataframes for boruta\n",
    "X_train_n = X_train.drop(['date', 'sales'], axis=1).values\n",
    "y_train_n = y_train.values.ravel()\n",
    "\n",
    "# Define Random Forest for boruta\n",
    "#rf = RandomForestRegressor(n_jobs = -1)\n",
    "\n",
    "# Define and fit Boruta algorithm\n",
    "#boruta = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42).fit(X_train_n, y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_selected = boruta.support_.tolist()\n",
    "\n",
    "# Best features\n",
    "#X_train_fs = X_train.drop(['date', 'sales'], axis = 1)\n",
    "#cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.to_list()\n",
    "\n",
    "# Features not selected\n",
    "#cols_not_selected_boruta = list(np.setdiff1d(X_train_fs.columns, cols_selected_boruta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_selected_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols_not_selected_boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Manual Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# added to boruta selection ['month_sin', 'week_of_year_sin']\n",
    "cols_selected_boruta = [\n",
    "     'store',\n",
    "     'promo',\n",
    "     'store_type',\n",
    "     'assortment',\n",
    "     'competition_distance',\n",
    "     'competition_open_since_month',\n",
    "     'competition_open_since_year',\n",
    "     'promo2',\n",
    "     'promo2_since_week',\n",
    "     'promo2_since_year',\n",
    "     'competition_time_month',\n",
    "     'promo_time_week',\n",
    "     'month_cos',\n",
    "     'month_sin',\n",
    "     'day_sin',\n",
    "     'day_cos',\n",
    "     'week_of_year_cos',\n",
    "     'week_of_year_sin',\n",
    "     'day_of_week_sin',\n",
    "     'day_of_week_cos']\n",
    "\n",
    "# We will need to use this columns later\n",
    "cols_to_add = ['date', 'sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_not_selected_boruta = [\n",
    "     'is_promo',\n",
    "     'month_sin',\n",
    "     'school_holiday',\n",
    "     'state_holiday_christmas',\n",
    "     'state_holiday_easter_holiday',\n",
    "     'state_holiday_public_holiday',\n",
    "     'state_holiday_regular_day',\n",
    "     'week_of_year_sin', \n",
    "     'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train[cols_selected_boruta]\n",
    "x_test = X_test[cols_selected_boruta]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux1 = x_test.copy()\n",
    "# aux1['sales'] = y_test.copy()\n",
    "\n",
    "# # Predictions\n",
    "# aux2 = aux1[['store', 'sales']].groupby('store').mean().reset_index().rename(columns={'sales': 'predictions'})\n",
    "# aux1 = pd.merge(aux1, aux2, how = 'left', on = 'store')\n",
    "# yhat_baseline = aux1['predictions']\n",
    "\n",
    "# # Performance\n",
    "\n",
    "# baseline_results = ml_error('Average Model', np.expm1(y_test), np.expm1(yhat_baseline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Linear Regression Regularized (Lasso / Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "298.237px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
